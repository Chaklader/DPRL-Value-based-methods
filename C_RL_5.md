

# C-5: Temporal-Difference Learning

1. TD Prediction
   - TD(0) Algorithm
   - Relation to Dynamic Programming
   - Bootstrapping and Sampling
   - Advantages and Limitations

2. Advantages of TD Methods
   - Comparison with Monte Carlo
   - Comparison with Dynamic Programming
   - Efficiency and Learning Speed
   - Empirical Results

3. Optimality of TD(0)
   - Batch Updating
   - Certainty Equivalence
   - Convergence Properties
   - Least-Squares Solution

4. SARSA: On-policy TD Control
   - Algorithm Description
   - Convergence Properties
   - Example Applications
   - Gridworld Experiments

5. Q-learning: Off-policy TD Control
   - Algorithm Description
   - Off-policy Learning
   - Convergence Properties
   - Cliff Walking Example

6. Expected SARSA
   - Algorithm Description
   - Reduction of Variance
   - Comparison with SARSA and Q-learning
   - Empirical Results

7. Maximization Bias and Double Learning
   - The Source of Bias
   - Double Q-learning
   - Empirical Evidence
   - Practical Implementations
